{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(audio_file:str, model:str)-> str:\n",
    "    model = whisper.load_model(model)\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_audio_file = r\"..\\resources\\input_eng.mp3\"\n",
    "hin_audio_file = r\"..\\resources\\input_hindi.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the different models for Sound to text-conversion using Whisper by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Depik\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\weya-takehome-QJnJCciM-py3.12\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi, this is a microphone test.\n",
      " Namaste, you have a prediction here.\n",
      " Hi, this is a microphone test.\n",
      " Namaste, یہ 1 parikshad.\n",
      " Hi, this is a microphone test.\n",
      " नमस्ते, यह एक परीक्षन है\n"
     ]
    }
   ],
   "source": [
    "# Tiny model\n",
    "print(speech_to_text(eng_audio_file, \"tiny\"))\n",
    "print(speech_to_text(hin_audio_file, \"tiny\"))\n",
    "\n",
    "# Base model\n",
    "print(speech_to_text(eng_audio_file, \"base\"))\n",
    "print(speech_to_text(hin_audio_file, \"base\"))\n",
    "\n",
    "# Small model\n",
    "print(speech_to_text(eng_audio_file, \"small\"))\n",
    "print(speech_to_text(hin_audio_file, \"small\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good observations can be seen for 'tiny' and 'base' models for english and 'small' model has slight better translation for hindi. But for the sake of complexity and time involved, we'll move forward with the base model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weya-takehome-QJnJCciM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
